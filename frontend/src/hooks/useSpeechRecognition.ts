import { useState, useRef, useCallback } from 'react'

interface UseSpeechRecognitionProps {
  onResult: (transcript: string, isFinal: boolean) => void
  onError?: (error: string) => void
  language?: string
  continuous?: boolean
}

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList
  resultIndex: number
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string
  message: string
}

export const useSpeechRecognition = ({
  onResult,
  onError,
  language = 'ko-KR',
  continuous = true,
}: UseSpeechRecognitionProps) => {
  const [isListening, setIsListening] = useState(false)
  const isSupported = !!(
    (window as any).SpeechRecognition || 
    (window as any).webkitSpeechRecognition
  )
  
  const recognitionRef = useRef<any>(null)
  const isListeningRef = useRef<boolean>(false)
  const shouldRestartRef = useRef<boolean>(false)
  const initialTextRef = useRef<string>('')
  const accumulatedTextRef = useRef<string>('')  // ëˆ„ì ëœ í™•ì • í…ìŠ¤íŠ¸
  
  // ëª¨ë°”ì¼ ê°ì§€
  const isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent)
  
  // ê°„ë‹¨í•œ ì¤‘ë³µ ë°©ì§€
  const lastSentTextRef = useRef<string>('')
  const lastInterimRef = useRef<string>('')  // ë§ˆì§€ë§‰ interim í…ìŠ¤íŠ¸

  // ìƒˆë¡œìš´ recognition ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
  const createRecognition = useCallback(() => {
    const SpeechRecognition = 
      (window as any).SpeechRecognition || 
      (window as any).webkitSpeechRecognition

    if (!SpeechRecognition) {
      return null
    }

    const recognition = new SpeechRecognition()
    
    // ëª¨ë°”ì¼ì—ì„œëŠ” continuous false, ë°ìŠ¤í¬í†±ì—ì„œëŠ” true
    recognition.continuous = isMobile ? false : continuous
    recognition.interimResults = true
    recognition.lang = language
    recognition.maxAlternatives = 1

    console.log('Recognition created - isMobile:', isMobile, 'continuous:', recognition.continuous)

    // ê²°ê³¼ ì²˜ë¦¬
    recognition.onresult = (event: SpeechRecognitionEvent) => {
      console.log('=== onresult START ===')
      console.log('resultIndex:', event.resultIndex, 'results.length:', event.results.length)
      
      // ê°€ì¥ ìµœê·¼ ê²°ê³¼ë§Œ ì²˜ë¦¬ (resultIndexë¶€í„°)
      let currentFinal = ''
      let currentInterim = ''
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i]
        const text = result[0].transcript.trim()
        
        console.log(`Result[${i}]: "${text}", isFinal: ${result.isFinal}`)
        
        if (result.isFinal) {
          currentFinal = text
        } else {
          currentInterim = text
        }
      }
      
      console.log('currentFinal:', currentFinal)
      console.log('currentInterim:', currentInterim)
      console.log('initialText:', initialTextRef.current)
      console.log('accumulatedText:', accumulatedTextRef.current)
      
      // ìµœì¢… í…ìŠ¤íŠ¸ ì¡°í•©
      let fullText = initialTextRef.current
      
      if (accumulatedTextRef.current) {
        fullText = fullText ? `${fullText} ${accumulatedTextRef.current}` : accumulatedTextRef.current
      }
      
      if (currentFinal) {
        fullText = fullText ? `${fullText} ${currentFinal}` : currentFinal
      } else if (currentInterim) {
        fullText = fullText ? `${fullText} ${currentInterim}` : currentInterim
      }
      
      fullText = fullText.trim()
      
      console.log('Composed fullText:', fullText)
      console.log('lastSent:', lastSentTextRef.current)
      
      // ì¤‘ë³µ ì²´í¬
      if (fullText === lastSentTextRef.current) {
        console.log('DUPLICATE - Ignoring')
        console.log('=== onresult END ===\n')
        return
      }
      
      // interimì´ ì´ì „ê³¼ ê°™ìœ¼ë©´ ë¬´ì‹œ (ëª¨ë°”ì¼ì—ì„œ ê°™ì€ interimì´ ë°˜ë³µë¨)
      if (!currentFinal && currentInterim === lastInterimRef.current) {
        console.log('SAME INTERIM - Ignoring')
        console.log('=== onresult END ===\n')
        return
      }
      
      if (!currentFinal) {
        lastInterimRef.current = currentInterim
      }
      
      // ë¹ˆ ê²°ê³¼ ë¬´ì‹œ
      if (!fullText || fullText === initialTextRef.current) {
        console.log('EMPTY - Ignoring')
        console.log('=== onresult END ===\n')
        return
      }
      
      const isFinalResult = !!currentFinal
      
      console.log('âœ… SENDING to onResult:', fullText, 'isFinal:', isFinalResult)
      
      lastSentTextRef.current = fullText
      onResult(fullText, isFinalResult)
      
      // final ê²°ê³¼ë©´ ëˆ„ì  - ì—¬ê¸°ê°€ í•µì‹¬!
      if (isFinalResult && currentFinal) {
        accumulatedTextRef.current = accumulatedTextRef.current 
          ? `${accumulatedTextRef.current} ${currentFinal}`.trim()
          : currentFinal
        lastInterimRef.current = ''
        console.log('âœ… Updated accumulatedText to:', accumulatedTextRef.current)
        
        // ì¤‘ìš”: lastSentTextë„ ì—…ë°ì´íŠ¸í•´ì„œ ë‹¤ìŒ ì‚¬ì´í´ì—ì„œ ì´ í…ìŠ¤íŠ¸ê°€ ê¸°ì¤€ì´ ë˜ë„ë¡
        const newBase = initialTextRef.current
          ? `${initialTextRef.current} ${accumulatedTextRef.current}`.trim()
          : accumulatedTextRef.current
        lastSentTextRef.current = newBase
        console.log('âœ… Updated lastSentText to:', lastSentTextRef.current)
      }
      
      console.log('=== onresult END ===\n')
    }

    // ì—ëŸ¬ ì²˜ë¦¬
    recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      console.error('Speech recognition error:', event.error)
      
      if (event.error === 'aborted' || event.error === 'no-speech') {
        return
      }
      
      let errorMessage = 'ìŒì„± ì¸ì‹ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤'
      
      switch (event.error) {
        case 'audio-capture':
          errorMessage = 'ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
          break
        case 'not-allowed':
          errorMessage = 'ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤'
          break
        case 'network':
          errorMessage = 'ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤'
          break
      }
      
      onError?.(errorMessage)
      setIsListening(false)
      isListeningRef.current = false
    }

    // ì¢…ë£Œ ì²˜ë¦¬
    recognition.onend = () => {
      console.log('========== Recognition ENDED ==========')
      console.log('shouldRestart:', shouldRestartRef.current)
      console.log('isListening:', isListeningRef.current)
      console.log('accumulatedText before restart:', accumulatedTextRef.current)
      
      // ëª¨ë°”ì¼ì—ì„œëŠ” ìë™ìœ¼ë¡œ ì¬ì‹œì‘ (continuous falseì´ë¯€ë¡œ)
      if (shouldRestartRef.current && isListeningRef.current) {
        console.log('ğŸ”„ Auto-restarting recognition...')
        console.log('Keeping accumulatedText:', accumulatedTextRef.current)
        
        setTimeout(() => {
          if (isListeningRef.current && recognitionRef.current) {
            try {
              recognitionRef.current.start()
              console.log('âœ… Recognition restarted successfully')
            } catch (err: any) {
              if (!err.message?.includes('already started')) {
                console.error('âŒ Failed to restart:', err)
                setIsListening(false)
                isListeningRef.current = false
              }
            }
          }
        }, 100)
      } else {
        console.log('ğŸ›‘ Not restarting - cleaning up')
        setIsListening(false)
        isListeningRef.current = false
      }
    }

    return recognition
  }, [language, continuous, isMobile, onResult, onError])

  // ìŒì„± ì¸ì‹ ì‹œì‘
  const startListening = useCallback((initialText: string = '') => {
    console.log('\n========== START LISTENING ==========')
    console.log('initialText:', initialText)
    console.log('isMobile:', isMobile)
    
    if (!isSupported) {
      onError?.('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤')
      return
    }

    if (isListeningRef.current) {
      console.log('Already listening')
      return
    }

    // ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop()
      } catch (e) {
        // ignore
      }
      recognitionRef.current = null
    }

    // ìƒíƒœ ì´ˆê¸°í™”
    initialTextRef.current = initialText
    accumulatedTextRef.current = ''
    lastSentTextRef.current = initialText
    lastInterimRef.current = ''

    // ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì‹œì‘
    recognitionRef.current = createRecognition()
    
    if (!recognitionRef.current) {
      onError?.('ìŒì„± ì¸ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
      return
    }

    try {
      recognitionRef.current.start()
      setIsListening(true)
      isListeningRef.current = true
      shouldRestartRef.current = true
      console.log('Recognition started successfully')
    } catch (err) {
      console.error('Failed to start:', err)
      onError?.('ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
      recognitionRef.current = null
      isListeningRef.current = false
      shouldRestartRef.current = false
    }
  }, [isSupported, isMobile, createRecognition, onError])

  // ìŒì„± ì¸ì‹ ì¤‘ì§€
  const stopListening = useCallback(() => {
    console.log('\n========== STOP LISTENING ==========')
    
    if (!recognitionRef.current || !isListeningRef.current) {
      return
    }

    try {
      shouldRestartRef.current = false
      isListeningRef.current = false
      
      recognitionRef.current.stop()
      recognitionRef.current = null
      
      setIsListening(false)
      initialTextRef.current = ''
      accumulatedTextRef.current = ''
      lastSentTextRef.current = ''
      lastInterimRef.current = ''
      
      console.log('Recognition stopped successfully')
    } catch (error) {
      console.error('Failed to stop:', error)
      shouldRestartRef.current = false
      recognitionRef.current = null
      setIsListening(false)
      isListeningRef.current = false
    }
  }, [])

  // í† ê¸€
  const toggleListening = useCallback(() => {
    if (isListeningRef.current) {
      stopListening()
    } else {
      startListening()
    }
  }, [startListening, stopListening])

  return {
    isListening,
    isSupported,
    startListening,
    stopListening,
    toggleListening,
  }
}
